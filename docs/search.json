[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a test of using Quarto to host tutorials/walkthroughs in Python and Julia"
  },
  {
    "objectID": "python_tutorials/python_example.html",
    "href": "python_tutorials/python_example.html",
    "title": "Python Notebook demo",
    "section": "",
    "text": "This notebook uses a Jupyter notebook to produce this page. This was written/edited using vscode\n\n\n(Most of this is vscode specific)\nFrom the terminal create a virtual environment in the python_tutorials directory:\npython -m venv venv\nsource venv/bin/activate\nInstall required modules:\npython -m pip install jupyter ipykernel jupyterlab\n(restart vscode if you did the above in a vscode terminal)\nLoad/create the notebook and set the notebook kernel to the vnenv you’ve created (button at the top right of the notebook)\n\n\n\nThis is just cut and pasted from https://jgori-ouistiti.github.io/CoopIHC/guide/learning.html\nI couldn’t get most of the examples to work in the documentation\n\n\nCode\nfrom coopihc.examples.simplepointing.envs import SimplePointingTask\nfrom coopihc.examples.simplepointing.users import CarefulPointer\nfrom coopihc.examples.simplepointing.assistants import ConstantCDGain\nfrom coopihc import State, Bundle\n\n\ntask = SimplePointingTask(gridsize=31, number_of_targets=8)\n\nunitcdgain = ConstantCDGain(1)\n\n\n# The policy to be trained has the simple action set [-5,-4,-3,-2,-1,0,1,2,3,,4,5]\n\naction_state = State()\n\naction_state[\"action\"] = discrete_array_element(low=-5, high=5)\n\n\nuser = CarefulPointer(override_policy=(BasePolicy, {\"action_state\": action_state}))\n\nbundle = Bundle(task=task, user=user, assistant=unitcdgain, reset_go_to=1)\n\nobservation = bundle.reset()\n\n\n\n\nCode\nprint(observation)\n\n\n----------------  -----------  -------------------------  -------------------\ngame_info         turn_index   1                          CatSet(4) - int8\n                  round_index  0                          Numeric() - int64\ntask_state        position     10                         Numeric() - int64\n                  targets      [ 1  5  7 13 14 15 19 22]  Numeric(8,) - int64\nuser_state        goal         15                         Numeric() - int64\nuser_action       action       0                          Numeric() - int64\nassistant_action  action       1                          CatSet(2) - int64\n----------------  -----------  -------------------------  -------------------\n\n\nLink to run it in Binder:\n\n\n\nBinder"
  },
  {
    "objectID": "python_tutorials/quartomarkdown.html",
    "href": "python_tutorials/quartomarkdown.html",
    "title": "Quarto document",
    "section": "",
    "text": "import numpy as np\n\nprint(1+2)\n\n3"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Available tutorials",
    "section": "",
    "text": "Available posts:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJulia / Quarto example\n\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2022\n\n\nDavid Mawdsley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPOMDPs in Julia\n\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2022\n\n\nDavid Mawdsley\n\n\n\n\n\n\n  \n\n\n\n\nPython Notebook demo\n\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2022\n\n\nDavid Mawdsley\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarto document\n\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2022\n\n\nDavid Mawdsley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "julia_tutorials/julia_example.html",
    "href": "julia_tutorials/julia_example.html",
    "title": "Julia / Quarto example",
    "section": "",
    "text": "This uses the example from the Quarto homepage\n\n\nPlot function pair (x(u), y(u)). See Figure 1 for an example.\n\nusing Plots\n\nplot(sin, \n     x->sin(2x), \n     0, \n     2π, \n     leg=false, \n     fill=(0,:lavender))\n\n\n\n\nFigure 1: Parametric Plots"
  },
  {
    "objectID": "julia_tutorials/pomdps.html",
    "href": "julia_tutorials/pomdps.html",
    "title": "POMDPs in Julia",
    "section": "",
    "text": "This is a longer Quarto document playing around with the POMDPs package in Julia to see how it works.\nUsing the quick start for POMDPs as an example\n\nusing POMDPs, QuickPOMDPs, POMDPModelTools, POMDPSimulators, QMDP\n\nm = QuickPOMDP(\n    states = [\"left\", \"right\"],\n    actions = [\"left\", \"right\", \"listen\"],\n    observations = [\"left\", \"right\"],\n    initialstate = Uniform([\"left\", \"right\"]),\n    discount = 0.95,\n\n    transition = function (s, a)\n        if a == \"listen\"\n            return Deterministic(s) # tiger stays behind the same door\n        else # a door is opened\n            return Uniform([\"left\", \"right\"]) # reset\n        end\n    end,\n\n    observation = function (s, a, sp)\n        if a == \"listen\"\n            if sp == \"left\"\n                return SparseCat([\"left\", \"right\"], [0.85, 0.15]) # sparse categorical distribution\n            else\n                return SparseCat([\"right\", \"left\"], [0.85, 0.15])\n            end\n        else\n            return Uniform([\"left\", \"right\"])\n        end\n    end,\n\n    reward = function (s, a)\n        if a == \"listen\"\n            return -1.0\n        elseif s == a # the tiger was found\n            return -100.0\n        else # the tiger was escaped\n            return 10.0\n        end\n    end\n)\n\nsolver = QMDPSolver()\npolicy = solve(solver, m)\n\nrsum = 0.0\nfor (s,b,a,o,r) in stepthrough(m, policy, \"s,b,a,o,r\", max_steps=10)\n    println(\"s: $s, b: $([s=>pdf(b,s) for s in states(m)]), a: $a, o: $o\")\n    global rsum += r\nend\nprintln(\"Undiscounted reward was $rsum.\")\n\ns: left, b: [\"left\" => 0.5, \"right\" => 0.5], a: listen, o: left\ns: left, b: [\"left\" => 0.85, \"right\" => 0.15], a: listen, o: left\ns: left, b: [\"left\" => 0.9697986577181208, \"right\" => 0.0302013422818792], a: right, o: left\ns: right, b: [\"left\" => 0.5, \"right\" => 0.5], a: listen, o: right\ns: right, b: [\"left\" => 0.15, \"right\" => 0.85], a: listen, o: right\ns: right, b: [\"left\" => 0.0302013422818792, \"right\" => 0.9697986577181208], a: left, o: left\ns: right, b: [\"left\" => 0.5, \"right\" => 0.5], a: listen, o: right\ns: right, b: [\"left\" => 0.15, \"right\" => 0.85], a: listen, o: right\ns: right, b: [\"left\" => 0.0302013422818792, \"right\" => 0.9697986577181208], a: left, o: left\ns: left, b: [\"left\" => 0.5, \"right\" => 0.5], a: listen, o: left\nUndiscounted reward was 23.0."
  }
]